{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83215e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485d414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/das/work/svn/Gits/a_Projects/101_clembench/clembench-runs'\n",
    "\n",
    "modprop_df = pd.read_csv(base_dir + '/Addenda/ModelAnalysis2024/Results/model_characteristics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4edcd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMPORARY, until PR is approved and file is at correct locaiton\n",
    "modprop_df = pd.read_csv('In/TMP_model_characteristics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c72f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/sxby0fb08xjbdx001s6j3wrh0000gq/T/ipykernel_74904/4263828293.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  v16.loc[:,'model'] = v16.iloc[:,0].str.replace(r'(\\w*)-t0.0.*', r'\\1').str.lower()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0                        yi-34b-chat\n",
       " 1                     yi-1.5-6b-chat\n",
       " 2                     yi-1.5-9b-chat\n",
       " 3                    yi-1.5-34b-chat\n",
       " 4                     tulu-2-dpo-70b\n",
       " 5                         claude-2.1\n",
       " 6            claude-3-haiku-20240307\n",
       " 7           claude-3-sonnet-20240229\n",
       " 8             claude-3-opus-20240229\n",
       " 9           dolphin-2.5-mixtral-8x7b\n",
       " 10                         command-r\n",
       " 11                    command-r-plus\n",
       " 12                   gemma-1.1-7b-it\n",
       " 13                       gemma-7b-it\n",
       " 14           gemini-1.5-flash-latest\n",
       " 15             gemini-1.5-pro-latest\n",
       " 16                    gemini-1.0-pro\n",
       " 17                   codegemma-7b-it\n",
       " 18                   gemma-1.1-2b-it\n",
       " 19       meta-llama-3-8b-instruct-hf\n",
       " 20      meta-llama-3-70b-instruct-hf\n",
       " 21               llama-2-70b-chat-hf\n",
       " 22         codellama-34b-instruct-hf\n",
       " 23          mistral-7b-instruct-v0.1\n",
       " 24        mixtral-8x7b-instruct-v0.1\n",
       " 25       mixtral-8x22b-instruct-v0.1\n",
       " 26               mistral-medium-2312\n",
       " 27                mistral-large-2402\n",
       " 28          mistral-7b-instruct-v0.2\n",
       " 29               starling-lm-7b-beta\n",
       " 30    nous-hermes-2-mixtral-8x7b-sft\n",
       " 31                gpt-3.5-turbo-0125\n",
       " 32                        gpt-4-0613\n",
       " 33                gpt-4-1106-preview\n",
       " 34                gpt-4-0125-preview\n",
       " 35            gpt-4-turbo-2024-04-09\n",
       " 36                 gpt-4o-2024-05-13\n",
       " 37                      openchat-3.5\n",
       " 38                 openchat-3.5-1210\n",
       " 39                 openchat-3.5-0106\n",
       " 40                 qwen1.5-0.5b-chat\n",
       " 41                 qwen1.5-1.8b-chat\n",
       " 42                   qwen1.5-7b-chat\n",
       " 43                  qwen1.5-14b-chat\n",
       " 44                  qwen1.5-32b-chat\n",
       " 45                  qwen1.5-72b-chat\n",
       " 46       sheep-duck-llama-2-70b-v1.1\n",
       " 47                 wizardlm-70b-v1.0\n",
       " Name: model, dtype: object,\n",
       " {'sheep-duck-llama-2-13b',\n",
       "  'sus-chat-34b',\n",
       "  'vicuna-13b-v1.5',\n",
       "  'vicuna-33b-v1.3',\n",
       "  'wizardlm-13b-v1.2'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modprop_df['Release Date'] = pd.to_datetime(modprop_df['Release Date'])\n",
    "modprop_df['Cut-off Date'] = pd.to_datetime(modprop_df['Cut-off Date'])\n",
    "\n",
    "## well fuck me. Turns out that the model names can contain trailing whitespaces...\n",
    "modprop_df['Model Name'] = modprop_df['Model Name'].str.strip()\n",
    "\n",
    "\n",
    "v16 = pd.read_csv(base_dir + '/v1.6/results.csv')\n",
    "#v16.loc[:,'model'] = v16.iloc[:,0].str.replace(r'(\\w*)-(?:hf-)?t0.0.*', r'\\1').str.lower()\n",
    "v16.loc[:,'model'] = v16.iloc[:,0].str.replace(r'(\\w*)-t0.0.*', r'\\1').str.lower()\n",
    "\n",
    "\n",
    "## f me part II: turns out that the results.csv has openchat_3.5, and modprop has openchat-3.5\n",
    "##  normalise to the latter\n",
    "v16.loc[v16.model == 'openchat_3.5', 'model'] = 'openchat-3.5'\n",
    "\n",
    "merged = pd.merge(left=modprop_df, right=v16, left_on='Model Name', right_on='model')\n",
    "\n",
    "(\n",
    " merged.model,\n",
    " set(v16.model) - set(merged.model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51815eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns = merged.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46abb930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model Provider', 'Model Name', 'Training Data Size (in trillions)',\n",
       "       'Cut-off Date', 'Parameter Size (in billions)', 'Release Date',\n",
       "       'Context Length (in thousands)', 'Commercial', 'Multilingual',\n",
       "       'Multimodal', 'Base Model', 'Instruction Tuning Data', 'Unnamed: 0',\n",
       "       '-, clemscore', 'all, Average % Played', 'all, Average Quality Score',\n",
       "       'imagegame, % Played', 'imagegame, Quality Score',\n",
       "       'imagegame, Quality Score (std)', 'privateshared, % Played',\n",
       "       'privateshared, Quality Score', 'privateshared, Quality Score (std)',\n",
       "       'referencegame, % Played', 'referencegame, Quality Score',\n",
       "       'referencegame, Quality Score (std)', 'taboo, % Played',\n",
       "       'taboo, Quality Score', 'taboo, Quality Score (std)',\n",
       "       'wordle, % Played', 'wordle, Quality Score',\n",
       "       'wordle, Quality Score (std)', 'wordle_withclue, % Played',\n",
       "       'wordle_withclue, Quality Score',\n",
       "       'wordle_withclue, Quality Score (std)', 'wordle_withcritic, % Played',\n",
       "       'wordle_withcritic, Quality Score',\n",
       "       'wordle_withcritic, Quality Score (std)', 'model'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f15b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Provider</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Base Model</th>\n",
       "      <th>-, clemscore</th>\n",
       "      <th>all, Average % Played</th>\n",
       "      <th>all, Average Quality Score</th>\n",
       "      <th>Instruction Tuning Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Google</td>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>1.82</td>\n",
       "      <td>17.78</td>\n",
       "      <td>10.23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Google</td>\n",
       "      <td>gemma-1.1-7b-it</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>14.14</td>\n",
       "      <td>49.67</td>\n",
       "      <td>28.46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Google</td>\n",
       "      <td>codegemma-7b-it</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>15.30</td>\n",
       "      <td>51.95</td>\n",
       "      <td>29.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Meta</td>\n",
       "      <td>llama-2-70b-chat-hf</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>llama-2-70b-hf</td>\n",
       "      <td>0.81</td>\n",
       "      <td>7.14</td>\n",
       "      <td>11.31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allenai</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>llama-2-70b-hf</td>\n",
       "      <td>12.62</td>\n",
       "      <td>49.76</td>\n",
       "      <td>25.37</td>\n",
       "      <td>ultrafeedback-binarized, tulu-v2-sft-mixture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wizardlmteam</td>\n",
       "      <td>wizardlm-70b-v1.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>llama-2-70b-hf</td>\n",
       "      <td>17.40</td>\n",
       "      <td>46.19</td>\n",
       "      <td>37.66</td>\n",
       "      <td>wizardlm-evol-instruct-v2-196k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Riid</td>\n",
       "      <td>sheep-duck-llama-2-70b-v1.1</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>llama-2-70b-hf</td>\n",
       "      <td>21.50</td>\n",
       "      <td>41.19</td>\n",
       "      <td>52.20</td>\n",
       "      <td>orca and alpaca inspired data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nexusflow</td>\n",
       "      <td>starling-lm-7b-beta</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>6.56</td>\n",
       "      <td>30.89</td>\n",
       "      <td>21.25</td>\n",
       "      <td>nectar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mistralai</td>\n",
       "      <td>mistral-7b-instruct-v0.1</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>8.01</td>\n",
       "      <td>37.14</td>\n",
       "      <td>21.58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Openchat</td>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>17.10</td>\n",
       "      <td>52.57</td>\n",
       "      <td>32.52</td>\n",
       "      <td>sharegpt, openorca, capybara, goat, glaive, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Openchat</td>\n",
       "      <td>openchat-3.5-1210</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>18.22</td>\n",
       "      <td>51.19</td>\n",
       "      <td>35.60</td>\n",
       "      <td>sharegpt, openorca, capybara, goat, glaive, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Openchat</td>\n",
       "      <td>openchat-3.5</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>23.64</td>\n",
       "      <td>63.52</td>\n",
       "      <td>37.22</td>\n",
       "      <td>sharegpt, openorca, capybara, goat, glaive, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mistralai</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>mixtral-8x7b-v0.1</td>\n",
       "      <td>8.17</td>\n",
       "      <td>47.62</td>\n",
       "      <td>17.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NousResearch</td>\n",
       "      <td>nous-hermes-2-mixtral-8x7b-sft</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>mixtral-8x7b-v0.1</td>\n",
       "      <td>11.95</td>\n",
       "      <td>39.68</td>\n",
       "      <td>30.12</td>\n",
       "      <td>openhermes-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cognitivecomputations</td>\n",
       "      <td>dolphin-2.5-mixtral-8x7b</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>mixtral-8x7b-v0.1</td>\n",
       "      <td>15.10</td>\n",
       "      <td>46.38</td>\n",
       "      <td>32.55</td>\n",
       "      <td>magicoder-oss-instruct-75k, magicoder-evol-ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Provider                      Model Name Release Date  \\\n",
       "13                 Google                     gemma-7b-it   2024-02-01   \n",
       "12                 Google                 gemma-1.1-7b-it   2024-04-01   \n",
       "17                 Google                 codegemma-7b-it   2024-04-01   \n",
       "21                   Meta             llama-2-70b-chat-hf   2023-07-01   \n",
       "4                 Allenai                  tulu-2-dpo-70b   2024-11-01   \n",
       "47           Wizardlmteam               wizardlm-70b-v1.0   2023-08-01   \n",
       "46                   Riid     sheep-duck-llama-2-70b-v1.1   2023-09-01   \n",
       "29              Nexusflow             starling-lm-7b-beta   2024-03-01   \n",
       "23              Mistralai        mistral-7b-instruct-v0.1   2023-09-01   \n",
       "39               Openchat               openchat-3.5-0106   2024-01-01   \n",
       "38               Openchat               openchat-3.5-1210   2023-12-01   \n",
       "37               Openchat                    openchat-3.5   2023-10-01   \n",
       "24              Mistralai      mixtral-8x7b-instruct-v0.1   2023-12-01   \n",
       "30           NousResearch  nous-hermes-2-mixtral-8x7b-sft   2024-01-01   \n",
       "9   cognitivecomputations        dolphin-2.5-mixtral-8x7b   2023-12-01   \n",
       "\n",
       "           Base Model  -, clemscore  all, Average % Played  \\\n",
       "13           gemma-7b          1.82                  17.78   \n",
       "12           gemma-7b         14.14                  49.67   \n",
       "17           gemma-7b         15.30                  51.95   \n",
       "21     llama-2-70b-hf          0.81                   7.14   \n",
       "4      llama-2-70b-hf         12.62                  49.76   \n",
       "47     llama-2-70b-hf         17.40                  46.19   \n",
       "46     llama-2-70b-hf         21.50                  41.19   \n",
       "29    mistral-7b-v0.1          6.56                  30.89   \n",
       "23    mistral-7b-v0.1          8.01                  37.14   \n",
       "39    mistral-7b-v0.1         17.10                  52.57   \n",
       "38    mistral-7b-v0.1         18.22                  51.19   \n",
       "37    mistral-7b-v0.1         23.64                  63.52   \n",
       "24  mixtral-8x7b-v0.1          8.17                  47.62   \n",
       "30  mixtral-8x7b-v0.1         11.95                  39.68   \n",
       "9   mixtral-8x7b-v0.1         15.10                  46.38   \n",
       "\n",
       "    all, Average Quality Score  \\\n",
       "13                       10.23   \n",
       "12                       28.46   \n",
       "17                       29.45   \n",
       "21                       11.31   \n",
       "4                        25.37   \n",
       "47                       37.66   \n",
       "46                       52.20   \n",
       "29                       21.25   \n",
       "23                       21.58   \n",
       "39                       32.52   \n",
       "38                       35.60   \n",
       "37                       37.22   \n",
       "24                       17.15   \n",
       "30                       30.12   \n",
       "9                        32.55   \n",
       "\n",
       "                              Instruction Tuning Data  \n",
       "13                                                NaN  \n",
       "12                                                NaN  \n",
       "17                                                NaN  \n",
       "21                                                NaN  \n",
       "4        ultrafeedback-binarized, tulu-v2-sft-mixture  \n",
       "47                     wizardlm-evol-instruct-v2-196k  \n",
       "46                      orca and alpaca inspired data  \n",
       "29                                             nectar  \n",
       "23                                                NaN  \n",
       "39  sharegpt, openorca, capybara, goat, glaive, me...  \n",
       "38  sharegpt, openorca, capybara, goat, glaive, me...  \n",
       "37  sharegpt, openorca, capybara, goat, glaive, me...  \n",
       "24                                                NaN  \n",
       "30                                     openhermes-2.5  \n",
       "9   magicoder-oss-instruct-75k, magicoder-evol-ins...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    merged[merged['Base Model']\n",
    "           .isin([b for b,c in merged['Base Model'].value_counts().items() if c > 1])]\n",
    "    [['Model Provider', 'Model Name', 'Release Date', 'Base Model',\n",
    "      '-, clemscore',  'all, Average % Played', 'all, Average Quality Score',\n",
    "      'Instruction Tuning Data']]\n",
    "    .sort_values(by=['Base Model', '-, clemscore'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33f3f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/sxby0fb08xjbdx001s6j3wrh0000gq/T/ipykernel_74904/3948124813.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  merged[merged['Base Model']\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    (\n",
    "        merged[merged['Base Model']\n",
    "               .isin([b for b,c in merged['Base Model'].value_counts().items() if c > 1])]\n",
    "        [['Base Model', 'Model Name', 'Model Provider', 'Release Date', \n",
    "          '-, clemscore',  'all, Average % Played', 'all, Average Quality Score',\n",
    "          'Instruction Tuning Data']]\n",
    "        .sort_values(by=['Base Model', '-, clemscore'])\n",
    "        .to_latex('Out/same_base_results.tex',\n",
    "                  header=['Base Model', 'Model Name', 'Model Provider', 'Release Date', \n",
    "                          'cs',  '% pl', 'q sc',\n",
    "                          'Instruction Tuning Data'],\n",
    "                  column_format='TTllrrrp{.3\\linewidth}',\n",
    "                  index=False,\n",
    "                  float_format=\"%.2f\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2fd6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Provider</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Data Size (in trillions)</th>\n",
       "      <th>Cut-off Date</th>\n",
       "      <th>Parameter Size (in billions)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Context Length (in thousands)</th>\n",
       "      <th>Commercial</th>\n",
       "      <th>Multilingual</th>\n",
       "      <th>Multimodal</th>\n",
       "      <th>Base Model</th>\n",
       "      <th>Instruction Tuning Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mistralai</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mixtral-8x7b-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Provider                  Model Name  \\\n",
       "27      Mistralai  mixtral-8x7b-instruct-v0.1   \n",
       "\n",
       "    Training Data Size (in trillions) Cut-off Date  \\\n",
       "27                                NaN          NaT   \n",
       "\n",
       "    Parameter Size (in billions) Release Date  Context Length (in thousands)  \\\n",
       "27                          45.0   2023-12-01                             32   \n",
       "\n",
       "    Commercial  Multilingual  Multimodal         Base Model  \\\n",
       "27           0             1           0  mixtral-8x7b-v0.1   \n",
       "\n",
       "   Instruction Tuning Data  \n",
       "27                     NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modprop_df.loc[modprop_df['Model Name'] == 'mixtral-8x7b-instruct-v0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e36e175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Provider</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Data Size (in trillions)</th>\n",
       "      <th>Cut-off Date</th>\n",
       "      <th>Parameter Size (in billions)</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Context Length (in thousands)</th>\n",
       "      <th>Commercial</th>\n",
       "      <th>Multilingual</th>\n",
       "      <th>Multimodal</th>\n",
       "      <th>Base Model</th>\n",
       "      <th>Instruction Tuning Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Openchat</td>\n",
       "      <td>openchat-3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>sharegpt, openorca, capybara, goat, glaive, me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Provider    Model Name  Training Data Size (in trillions)  \\\n",
       "40       Openchat  openchat-3.5                                NaN   \n",
       "\n",
       "   Cut-off Date  Parameter Size (in billions) Release Date  \\\n",
       "40          NaT                           7.0   2023-10-01   \n",
       "\n",
       "    Context Length (in thousands)  Commercial  Multilingual  Multimodal  \\\n",
       "40                              8           0             0           0   \n",
       "\n",
       "         Base Model                            Instruction Tuning Data  \n",
       "40  mistral-7b-v0.1  sharegpt, openorca, capybara, goat, glaive, me...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modprop_df.loc[modprop_df['Model Name'] == 'openchat-3.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b753d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
